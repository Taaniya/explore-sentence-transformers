{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdd0dcOLAz1pQXzwjgY9c5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taaniya/sentence-embeddings-with-bert/blob/main/sentence_embeddings_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSrys8lqDcLs"
      },
      "outputs": [],
      "source": [
        "! pip install transformers sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "uS6fFvElDgak"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Pooling - Take attention mask into account for correct averaging\n",
        "\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]         #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"
      ],
      "metadata": {
        "id": "UaEFkwioDoC1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentences we want sentence embeddings for\n",
        "sentences = ['This is an example sentence', 'Each sentence is converted']"
      ],
      "metadata": {
        "id": "y4y4XLLGDn_X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model from HuggingFace Hub\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
        "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')"
      ],
      "metadata": {
        "id": "dfgN43gKDn9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CdE0Ry7FaOX",
        "outputId": "18aa59fe-b6ea-48d2-b298-f6ff757f234e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MPNetModel(\n",
              "  (embeddings): MPNetEmbeddings(\n",
              "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): MPNetEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x MPNetLayer(\n",
              "        (attention): MPNetAttention(\n",
              "          (attn): MPNetSelfAttention(\n",
              "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (intermediate): MPNetIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): MPNetOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (relative_attention_bias): Embedding(32, 12)\n",
              "  )\n",
              "  (pooler): MPNetPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences\n",
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "sxyguT3QDn7S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute token embeddings\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)"
      ],
      "metadata": {
        "id": "jyxfpxQODn5G"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform pooling\n",
        "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"
      ],
      "metadata": {
        "id": "FOlss1hBDn26"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkJSBSRRFIgf",
        "outputId": "aa573c01-2802-4932-e76b-a9c4e105f873"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize embeddings\n",
        "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n"
      ],
      "metadata": {
        "id": "vrSBm9lZEFwF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sentence embeddings:\")\n",
        "print(sentence_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC24xUa-EFsv",
        "outputId": "adf4716d-40ff-4715-816b-9d02f8c96c69"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence embeddings:\n",
            "tensor([[ 0.0225, -0.0783, -0.0230,  ..., -0.0083,  0.0265, -0.0020],\n",
            "        [ 0.0417,  0.0011, -0.0155,  ..., -0.0218, -0.0636, -0.0088]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6v8s57xEFqV",
        "outputId": "89c13c5e-902f-490c-f448-9d36d01a4974"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using sentence transformers library"
      ],
      "metadata": {
        "id": "nbuuaBRDFwZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "lPrazZMTEFoC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
      ],
      "metadata": {
        "id": "mLDfpAPoF2zu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5ktlZlIHBeh",
        "outputId": "3088d112-0371-4b50-da4c-b802f59c9f26"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
              "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
              "  (2): Normalize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SBERT architecture uses mean pooling strategy on the output by default."
      ],
      "metadata": {
        "id": "XXNdDgrEHjdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = model.encode(sentences)"
      ],
      "metadata": {
        "id": "QTHVbOlHF72h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WELOLg5bF9_P",
        "outputId": "9326133c-a2f8-4d7b-81ec-d45d858e0155"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.02250258 -0.07829181 -0.02303076 ... -0.00827927  0.0265269\n",
            "  -0.00201898]\n",
            " [ 0.04170236  0.0010974  -0.01553419 ... -0.02181627 -0.06359357\n",
            "  -0.00875284]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n_qEl7AGANs",
        "outputId": "56d37dbb-475c-4d9c-ce5b-67f97e715895"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the embeddings by the two approaches"
      ],
      "metadata": {
        "id": "yRkR7RtgGkYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.array_equal(sentence_embeddings, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACHsWkiaGOIi",
        "outputId": "d2ed587a-ea95-47a6-a39d-388d161fca35"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### References\n",
        "* https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
        "* [SBERT paper](https://arxiv.org/pdf/1908.10084.pdf)\n",
        "* https://www.sbert.net/index.html"
      ],
      "metadata": {
        "id": "tE1-LZObDjhY"
      }
    }
  ]
}